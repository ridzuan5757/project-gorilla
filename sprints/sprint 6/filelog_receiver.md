# Filelog Receiver

This document outlines the design and implementation of Filelog Receiver that will be 
built into OpenTelemetry Collector container. This receiver will enable the ingestion
of log data from files such as `syslog` and `journal-systemd` which can then be
processed, exported to various backends supported by OpenTelemetry.

## Linux Log Files

Log files are crucial for monitoring and troubleshooting the operating system and various
processes runing on it. They provide a detailed record of system actities, errors as well
as events triggered by various processes that are currently running. All of these files
are typically stored in `/var/log/` directory. Some of the important log files that will
be monitored as part of the Proactive Monitoring Initiative are as shown below:

|***Name***|***Purpose***|***Content***|***Usage***|
|---|---|---|---|
|`syslog`|General System log.|Register system-wide messages and logs from various system services.|Useful for debugging general system issues.|
|`auth`|Authentication log.|Records authentication-related events, such as user login attempts and authentication failures.|SOC 2 Type II security auditing and tracting any unauthorized access attempts.|
|`kern`|Kernel log.|Logs generated by Linux kernel.|Diagnosing issues on kernel level as well as devices / hardware problems.|
|`boot`|System boot log.|Capture ring buffer message during system boot.|Troubleshooting boot issues and hardware detection problems.|
|`daemon`|Daemon log.|Logs from various background services.|Diganose issues with system services.|
|`wtmp|btmp`|Loging, logout and bad login log.|`wtmp` records all login and logout events while `wtmp` records all failed login attempts.|Tracking user sessions and detecting any login breach.|

# Motivation
- Continuously monitor specific log files for new entries.
- Parse log entries according to user-defined formats.
- Gracefully handle errors such as file rotation and permission issues.
- Ensure minimal impact on the system resource.

# Filelog Receiver

`operator` is the basic unit of the log processing. Each processor fulfills a simple responsibility, such as reading lines from a file, or pasing JSON from a field. `operator`s are then chained together in a pipeline to achieve a desired result.

The operators that are available are as shown below:

| **Parsers**       | **General Purpose** |
|-------------------|---------------------|
| CSV Parser        | `add`               |
| JSON Parser       | `copy`              |
| JSON Array Parser | `filter`            |
| Regex Parser      | `flatten`           |
| Scope Name Parser | `move`              |
| Syslog Parser     | `noop`              |
| Severity Parser   | `recombine`         |
| Time Parser       | `remove`            |
| Trace Parser      | `retain`            |
| URI Parser        | `router`            |
| Key-Value Parser  | `unquote`           |
| Container         | `assign_keys`       |

`pipeline` is made up of sequence of `operators`. The `pipeline` define how this receiver should input, process and output logs. In the `pipeline`, the `operator` will output to the next `operator` in the pipeline. The last `operator` in the `pipeline` will emit from the `receiver`. Optionally, the `output` parameter can be linked to another `operator` to which logs will be passed directly.

In addition to the receiver configuration, the OpenTelemetry Collector
installation in `k8s` will need access to the logs it wants to collect. This would means every log files that need to be fed into the infrastructure has to be mounted as `volumes` and `volumeMounts` to the collector manifest file.

# Specification

For this implementation, 2 type of log files shall be parsed and fed into the Proactive Monitoring infrastructure. `router` will be used to redirect both of these type to their respective parser. `json_parser` will be used to parse any log file in JSON format while the rest of the log files is assumed to follow `syslog` convention and hence fed into `syslog_parser`. Now that every logs are reshaped into OTLP format, severity information and timestamp are then added using `severity_parser` and `timestamp_parser` respectively.

# Tasks
- Create a configuration file for parsing JSON and Syslog log files.
- Set up volume mounting for each log file that needs to be processed.